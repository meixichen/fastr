#' Fit a latent factor model to single or multiple neuron spike trains
#'
#' @param data A `n_cell x n_bin x n_trial` (multiple neurons)  or `n_bin x n_trial`
#' (single neuron) array of binary spike trains. See details for if the spike train
#' data is in the form of spike times.
#' @param dt Scalar. Length of each time bin for time discretization of spike trains.
#' @param n_factor Integer. Number of independent factors in factor analysis.
#' @param init A named list of initial values for the parameter vectors `log_a` and
#' `log_k`  both of length `n_cell`, and the lower triangular entries of the loading
#' matrix `Lt` of length `n_cell*n_factor-n_factor*(n_factor-1)/2`.
#' Optionally the initial values of the latent path states can also be provided
#' in the list named as `x` which should be the same dimension as `data`.
#' It `x` is not provided, initial values will be generated by bridge sampling.
#' If `method="2steps"`, only the initial values for the lower triangular loading
#' matrix can to be provided in the form of `list(Lt = Lt_init_values)`. Default is
#' `list(Lt=rep(1, n_cell*n_factor-n_factor*(n_factor-1)/2))` if 2-step method is used,
#' or
#' `list(log_k=logk_mle, log_a=loga_mle, Lt=rep(1, n_cell*n_factor-n_factor*(n_factor-1)/2))` if joint method is used.
#' @param method Estimation method: "2step" or "joint".
#' Default is "2step" : the first step is estimating drift `a` and threshold `k`
#' marginally using an inverse Gaussian model for each neuron independently, and the
#' second step is estimating the factor loading matrix with `a_hat` and `k_hat` as
#' plug-ins the joint likelihood. "joint" method estimates all parameters jointly,
#' hence more computationally intensive.
#' @param lam Scalar. Penalization parameter for the loading matrix elements. Default
#' is `lam=ifelse(n_cell<10, 1, 0.5)`.
#' @param nu Scalar. Parameter that controls the "steepness" around 0 of the sigmoid
#' function applied at the spike data likelihood layer. Default is 15.
#' @param woodbury Use the Woodbury matrix identity to speed up the calculation of
#' the covariance matrix? Default is T.
#' @param silent Suppress model fitting messages?
#' @param adfun_only Only outputs of ADFun created by TMB? This is for debugging
#' purposes only.
#' @param simplified Should a simplified output be given? If true, the output
#' saves 80 times more space.
#' @param control A list of control parameters to pass to `nlminb()`.
#' @param ignore_random Ignore random effect? If TRUE, latent paths are not integrated
#' out in the model. This can be helpful for checking the marginal likelihood.
#' @param ... Additional arguments to be passed to the optimization function
#' `nlminb()`
#' @details If the spike train data comes in the form of spike times, it can be
#' converted to the format accepted by `fastr_fit()` using the function `num2bin()`.
#' @return A list of class `fastr_fit` containing the following objects:
#' - time: time taken for model fitting in seconds,
#' - rate_hat: estimates of the firing rates (alpha/k),
#' - lam_hat: estimates of the inverse Gaussian lambda parameters,
#' - se_ig (if simplified=FALSE): SEs of the IG parameters (rates and lambda),
#' - log_a_hat: estimates of log drift parameters `a`,
#' - log_k_hat: estimates of log threshold parameters `k`,
#' - loga_se: standard errors of `log_a_hat`,
#' - logk_se: standard errors of `log_k_hat`,
#' - lmat_hat: estimate of the loading matrix L,
#' - lmat_varimax: Varimax-transformed loading matrix estimate,
#' - lmat_unnorm_hat: estimate of the unnormalized L
#' - lmat_unnorm_cov: covariance matrix of the unnormalized L,
#' - paths: point estimates of the latent paths. Use `array(output$paths,
#' c(n_cell,n_bin,n_trial)` to convert the estimated paths to an array format.
#' - paths_se: corresponding standard errors for the paths.
#' - env: Other objects in the environment created during model fitting. If
#' simplified=FALSE, TMB objects is included here.
#' @export

fastr_fit <- function(data, dt, n_factor, init=NULL, method="2step", lam=NULL, nu=15,
		   woodbury=TRUE, silent=FALSE, adfun_only=FALSE, simplified=TRUE,
		   control=list(eval.max=500, iter.max=500), ignore_random=FALSE, ...){
  if (length(dim(data))==3){ # multiple neurons
    n_cell <- dim(data)[1]
    n_bin <- dim(data)[2]
    n_trial <- dim(data)[3]
  } else if (length(dim(data))==2){ # single neuron
    n_cell <- 1
    n_bin <- dim(data)[1]
    n_trial <- dim(data)[2]
    woodbury <- FALSE # DO NOT use the woodbury for single neuron model as it will crash R
    n_factor <- 1 # override whatever n_factor that is specified
    method <- "joint" # canNOT use two-step method for single neuron model
  } else{
    stop("Check the dimension of data, which must be either `n_cell x n_bin x n_trial`, or
	 `n_bin x n_trial` for a single neuron.")
  }

  if (n_factor < 1) stop("n_factor must be an integer >= 1.")

  # Get k and a MLE
  all_mle <- get_ig_mle(data, dt)
  log_k_hat <- all_mle$log_k
  log_a_hat <- all_mle$log_a
  hess_ak <- all_mle$hess_ak
  rate_hat <- all_mle$gamma
  lam_hat <- all_mle$lambda
  se_ig <- all_mle$se_ig
  marg_cov <- solve(-hess_ak)
  logk_se <- diag(marg_cov)[1:n_cell]
  loga_se <- diag(marg_cov)[(n_cell+1):(2*n_cell)]

  if (method == "2step"){
    if (is.null(init)){
      Lt <- rep(1, n_cell*n_factor-n_factor*(n_factor-1)/2)
    }
    else{
      Lt <- init$Lt
    }
    if (is.null(init$x)){
      x <- prop_paths(data, dt, log_k_hat, log_a_hat)
    }
    else{
      x <- init$x
    }
    init_param <- list(log_k = log_k_hat,
		       log_a = log_a_hat,
		       Lt = Lt,
		       x = x)
    map <- list(log_k=rep(factor(NA), n_cell),
                log_a=rep(factor(NA), n_cell))
  }
  else if (method == "joint"){
    if (is.null(init)){
      init_param <- list(log_k = log_k_hat,
			 log_a = log_a_hat,
                         Lt = rep(1, n_cell*n_factor-n_factor*(n_factor-1)/2),
			 x = prop_paths(data, dt, log_k_hat, log_a_hat))
    }
    else{
      if (is.null(init$x)){
        x <- prop_paths(data, dt, init$log_k, init$log_a)
      }
      else{
 	x <- init$x
      }
      init_param <- list(log_k = init$log_k,
			 log_a = init$log_a,
			 Lt = init$Lt,
			 x = x)
    }
    map <- NULL
  }
  else{
    stop("method must be one of '2step' or 'joint'.")
  }


  if (n_cell == 1){
    model_choice <- "single_model"
    data <- list(model=model_choice, dt=dt, Y=data, nu=as.double(nu))
    init_param <- init_param[-which(names(init_param)=="Lt")] # rm Lt from param list
  } else{
    model_choice <- ifelse(woodbury, "factor_model_eff", "factor_model")
    lam <- ifelse(n_cell<10, 1, 0.5)
    data <- list(model=model_choice, n_factor=n_factor, dt=dt, Y=data,
   	         lam=as.double(lam), nu=as.double(nu))
  }

  if (!silent) cat("Building the ADFun...\n")
  if (ignore_random){
    random <- NULL
  } else {
    random <- "x"
  }
  adfun <- TMB::MakeADFun(data=data,
                          parameters=init_param,
			  map = map,
			  random = random,
			  DLL = "fastr_TMBExports",
			  silent = silent)
  if (!adfun_only){
    start_t <- Sys.time()
    fit <- nlminb(adfun$par, adfun$fn, adfun$gr, control=control)
    time_nlminb <- difftime(Sys.time(), start_t, units="secs")
    if (!silent) cat("Finished optimization. Starting sdreport...\n")
    rep <- TMB::sdreport(adfun, getJointPrecision = TRUE)
    time_sdrep <- difftime(Sys.time(), start_t, units="secs") - time_nlminb
    if (method == "joint"){
      k_ind <- which(names(fit$par)=="log_k")
      a_ind <- which(names(fit$par)=="log_a")
      log_k_hat <- fit$par[k_ind]
      log_a_hat <- fit$par[a_ind]
      all_se <- diag(rep$cov.fixed)
      logk_se <- all_se[k_ind]
      loga_se <- all_se[a_ind]
    }
    t_taken <- as.numeric(difftime(Sys.time(), start_t, units="secs"))
    if (n_factor==1){ # no loading mat if only 1 factor is used
      lmat_hat <- lmat_varimax <- lmat_unnorm_hat <- lmat_unnorm_cov <- NULL
    }
    else{
      lmat_hat <- get_FA_estim(fit, n_cell=n_cell, n_factor=n_factor)$L
      lmat_varimax <- varimax(lmat_hat)$loadings[1:n_cell,]
      lmat_unnorm_hat <- rep$par.fixed[which(names(rep$par.fixed)=="Lt")]
      lmat_unnorm_cov <- rep$cov.fixed[which(colnames(rep$cov.fixed)=="Lt"),
       				     which(colnames(rep$cov.fixed)=="Lt")]
    }
    env <- list(start_time = start_t,
		time_nlminb = time_nlminb,
		time_sdrep = time_sdrep,
                nlminb_fit = fit,
                tmb_report = rep,
                n_factor = n_factor,
                n_cell = n_cell,
                n_bin = n_bin,
                n_trial = n_trial,
                dt = dt)
    out <- list(time = t_taken,
		rate_hat = rate_hat,
		lam_hat = lam_hat,
		se_ig = se_ig,
		log_k_hat = log_k_hat,
		log_a_hat = log_a_hat,
	        logk_se = logk_se,
		loga_se = loga_se,
		marg_cov = marg_cov,
		lmat_hat = lmat_hat,
		lmat_varimax = lmat_varimax,
		lmat_unnorm_hat = lmat_unnorm_hat,
		lmat_unnorm_cov = lmat_unnorm_cov,
		paths = rep$par.random,
		paths_se = sqrt(rep$diag.cov.random),
		env = env)
    class(out) <- "fastr_fit"
    if (simplified) out <- simplify_output(out)
    return(out)
  }
  else{
    return(adfun)
  }
 }


#' Obtain L and a/k from model fit
#'
#' @param mod_fit Fitted factor model output by nlminb(adfun), or a vector of off
#' diagonal elements of the loading matrix.
#' @param n_cell Number of neurons
#' @param n_factor Number of factors
#' @return A list of normalized L matrix and, if the model fit is provided, the firing
#' rate ratio (a/k)
#' @noRd
get_FA_estim <- function(mod_fit, n_cell, n_factor){
  if (!("par" %in% names(mod_fit))){
    if (length(mod_fit) == n_cell*n_factor-n_factor*(n_factor-1)/2){
      off_diag_L_est <- mod_fit
      fi <- NULL
    } else{
      stop("mod_fit should be either an output of nlminb/optim, or a vector of Lt estimates.")
    }
  } else{
    estimates <- mod_fit$par
    off_diag_L_est <- estimates[names(estimates)=="Lt"]
    fi <- unname(exp(estimates[names(estimates)=="log_a"]-
                     estimates[names(estimates)=="log_k"]))
    fi <- round(fi, 3)
  }
  L_est <- matrix(0, nrow=n_cell, ncol=n_factor)
  L_est[lower.tri(L_est, diag=TRUE)] <- off_diag_L_est
  psi <- rep(1, n_cell)
  res <- norm_mat(L_est, psi, 3)

  return(list(
    L=res$L,
    fi=fi
  ))
}

#' Normalize the rows of L and Psi
#'
#' @param L Loading matrix
#' @param psi Vector of diagonal elements of the error term matrix
#' @param prec Precision of the output
#' @return A list containing the normalized L matrix and the diagonal vector of Psi, such that the norm of each row of L plus the diagonal of Psi equals 1
#' @noRd
norm_mat <- function(L, psi, prec){
  n_cell <- nrow(L)
  for (i in 1:n_cell){
    norm2 <- sum(L[i,]^2) + psi[i]
    L[i,] <- L[i,]/sqrt(norm2)
    psi[i] <- psi[i]/norm2
  }
  return(list(L=round(L, prec), psi=round(psi, prec)))
}

#' Propose an initial path (x) given parameters k and alpha
#'
#' @param Y A n x r array or q x n x r array of data where q is num of neurons, n is num of bins, r is num of trials
#' @param dt Length of time bin
#' @param log_k Length q vector of log threshold parameters
#' @param log_a Length q vector of log drift parameters
#' @noRd
prop_paths <- function(Y, dt, log_k, log_a){
  k <- exp(log_k)
  alpha <- exp(log_a)
  dimY <- dim(Y)
  # If only 1 neuron
  if (length(dimY) == 2){
    if (length(log_k)!=1 | length(log_a)!=1) stop("Assume one neuron. Check dimensions of arguemnts.    ")
    n <- dimY[1]
    r <- dimY[2]
    output <- array(NA, dim = c(n, r))
    for (i in 1:r){
      y <- Y[,i]
      U <- (cumsum(y) + 1)*k # upper bounds for neuron path
      L <- cumsum(y)*k # lower bounds for neuron path
      prop_x <- rep(0, n)
      for (j in 1:n){
        if (j > 1){
          last_x <- prop_x[j-1]
        }
        else{
          last_x <- 0
        }
        prop_x[j] <- truncnorm::rtruncnorm(1, a=L[j], b=U[j], mean=last_x+alpha*dt, sd=sqrt(dt))
      }
      output[ ,i] <- prop_x
    }
    return(output)
  }
  # If there are more than 1 neuron
  q <- dimY[1] # num of neurons
  n <- dimY[2] # num of bins
  r <- dimY[3] # num of trials
  output <- array(NA, dim = c(q, n, r))
  for (i in 1:r){
    for (w in 1:q){
      y <- Y[w,,i]
      U <- (cumsum(y) + 1)*k[w] # upper bounds for neuron path
      L <- cumsum(y)*k[w] # lower bound
      prop_x <- rep(0, n)
      for (j in 1:n){
        if (j > 1){
          last_x <- prop_x[j-1]
        }
        else{
          last_x <- 0
        }
        prop_x[j] <- truncnorm::rtruncnorm(1, a=L[j], b=U[j], mean=last_x+alpha[w]*dt, sd=sqrt(dt))
      }
      output[w, ,i] <- prop_x
    }
  }
  output
}


#' Calculate the MLEs for parameters of an inverse Gaussian distribution
#'
#' @param Y A `q x n x r` or `n x r` array of 0/1 spike trains
#' where `q` is the number of cells,
#' `n` is the number of time bins, and `r` is the number of trials.
#' @param dt Scalar of length of the bins.
#' @return A list of MLEs and Hessian matrix of the (log) parameters
#' c(log_k, log_a) and the SEs of the IG parameters c(1/mu, lambda).
#' @details Let T be the vector of all ISIs. MLEs are calculated by
#' ```
#' \hat{\mu} = \bar{T}, \hat{\lambda} = n/\sum_{i=1}^n(1/T_i - 1/\bar{T}).
#' ```
#' If this IG distribution represents the distribution of first passage time of a
#' Wiener process with threshold k, drift alpha and variance sigma^2, then mu =
#' k/alpha, lambda=k^2/sigma^2.
#' @export
get_ig_mle <- function(Y, dt){
  if (length(dim(Y)) == 3) { # More than 1 trial
    n_cell <- dim(Y)[1]
  } else if (length(dim(Y)) == 2) { # only one neuron
    n_cell <- 1
  } else {
    stop("Check the dimension of Y.")
  }
  all_ISI <- lapply(1:n_cell, bin2isi, Y=Y, dt=dt)

  hess_ak <- matrix(0, nrow=2*n_cell, ncol=2*n_cell)
  se_ig <- rep(NA, n_cell*2) # not storing the hessian for the ig param because it is diagonal
  mu_hat <- rep(NA, n_cell)
  gamma_hat <- rep(NA, n_cell)
  lam_hat <- rep(NA, n_cell)
  log_k_hat <- rep(NA, n_cell)
  log_a_hat <- rep(NA, n_cell)

  for (i in 1:n_cell){
    neuron_i_isi <- all_ISI[[i]]
    n <- length(neuron_i_isi)
    mu_hat[i] <- mean(neuron_i_isi)
    gamma_hat[i] <- 1/mu_hat[i]
    lam_hat[i] <- n/sum(1/neuron_i_isi - 1/mu_hat[i])
    log_k_hat[i] <- 0.5*log(lam_hat[i])
    log_a_hat[i] <- log_k_hat[i] - log(mu_hat[i])
    # Construct Hessian for the a/k parameterization
    temp_ak <- n*exp(log_k_hat[i]+log_a_hat[i])
    hess_ak_i <- matrix(c(-temp_ak-2*n,temp_ak,temp_ak,-temp_ak), ncol=2)
    idx <- (2*(i-1)+1):(2*i)
    hess_ak[idx, idx] <- hess_ak_i
    # Get SEs for the IG parameterizatino with gamma and lambda
    se_ig[(2*i-1): (2*i)] <- sqrt(1/c(n*lam_hat[i]/gamma_hat[i],
                            n/(2*lam_hat[i]^2)))
  }
  names <- paste0(c("log_k", "log_a"), rep(1:n_cell, each=2))
  colnames(hess_ak) <- names
  rownames(hess_ak) <- names
  neworder <- c(seq(1,(2*n_cell), by=2), seq(2, (2*n_cell), by=2))
  hess_ak <- hess_ak[neworder, neworder] # order by k and then a

  names_ig <- paste0(c("gamma", "lambda"), rep(1:n_cell, each=2))
  names(se_ig) <- names_ig
  se_ig <- se_ig[neworder] # order by gamma and then lambda

  return(list(log_k=log_k_hat, log_a=log_a_hat, hess_ak=hess_ak,
              gamma=gamma_hat, lambda=lam_hat, se_ig=se_ig))
}

#' Makes simplified output from an object of class `fastr_fit`
#'
#' @param fobj An object of class `fastr_fit`.
#' @param ... Additional arguments.
#' @return A list of class `fastr_fit`.
#' @details This is both a helper function used within the function `fastr_fit()` and
#' can also be used standalone.
#' @export
simplify_output <- function(fobj, ...){
  if (!inherits(fobj, "fastr_fit")) stop("`fobj` must be an object of class `fastr_fit`.")
  n_cell <- fobj$env$n_cell
  ig_params <- list(lam_hat = fobj$lam_hat,
                    lam_se = fobj$se_ig[(n_cell+1):(2*n_cell)],
                    log_k_hat = fobj$log_k_hat,
                    log_a_hat = fobj$log_a_hat,
                    logk_se = fobj$logk_se,
                    loga_se = fobj$loga_se
                    )
  env <- list(start_time = fobj$env$start_time,
              time_nlminb = fobj$env$time_nlminb,
              time_sdrep = fobj$env$time_sdrep,
              n_factor = fobj$env$n_factor,
              n_cell = fobj$env$n_cell,
              n_bin = fobj$env$n_bin,
              n_trial = fobj$env$n_trial,
              dt = fobj$env$dt
              )
  out <- list(time = fobj$time,
              rate_hat = fobj$rate_hat,
              rate_se = fobj$se_ig[1:n_cell],
              lmat_hat = fobj$lmat_hat,
              lmat_varimax = fobj$lmat_varimax,
              lmat_unnorm_hat = fobj$lmat_unnorm_hat,
              lmat_unnorm_cov = fobj$lmat_unnorm_cov,
              paths = fobj$paths,
              paths_se = fobj$paths_se,
              rho_se = fobj$env$tmb_report$sd,
              ig_params = ig_params,
              env = env
              )
  class(out) <- "fastr_fit"
  return(out)
}

